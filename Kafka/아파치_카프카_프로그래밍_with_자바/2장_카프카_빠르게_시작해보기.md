# 2장 카프카 빠르게 시작해보기
카프카 브로커의 기본 포트는 9092이고 주키퍼의 기본 포트는 2181이다. EC2에 설치된 브로커에 접속하기 위해서는 보안 그룹의 Inbound 설정에 9092와 2181 포트를 열어야 한다.  
  
## 주키퍼, 카프카 브로커 실행
카프카 바이너리 패키지를 다운로드한다.  
```bash
wget http://archive.apache.org/dist/kafka/2.5.0/kafka+2.12-2.5.0.tgz
tar xvf kafka_2.12-2.5.0.tgz
```
xvf 옵션으로 아카이브에서 파일을 추출하고, 파일의 이름을 지정할 수 있다. v 옵션은 명령이 수행되는 동안 진행 상황을 자세히 보여준다.  
  
카프카 브로커를 실행하기 위해서는 힙 메모리 설정이 필요하다.  
카프카 패키지의 힙 메모리는 카프카 브로커는 1G, 주키퍼는 512MB로 기본 설정되어 있다.

`KAFKA_HEAP_OPTS` 환경변수를 힙 메모리 사이즈와 함께 지정하면 된다.  
터미널 세션이 종료되고 나면 초기화되는 것을 막기 위해 환경변수 선언문을 ~/.bashrc 파일에 넣자.  
```text
~/ 는 사용자의 홈 디렉토리를 나타낸다.
echo ~/ 출력 시 
/home/ec2-user/ 가 나온다.
```
카프카 브로커 실행 시 메모리를 설정하는 부분은 kafka-server-start.sh 스크립트 내부에서 확인할 수 있다.  
```bash
if ["x$KAFKA_HEAP_OPTS" = "x"]; then
    export KAFKA_HEAP_OPTS="-Xmx1G -Xms1G"
fi
```
일반적으로 카프카 브로커를 실행할 때 `-daemon` 옵션을 붙여 백그라운드로 실행하는 것이 일반적인 운영방법이다.  
  
그 다음으로 카프카 브로커 실행 옵션을 설정해야 한다.(config/server.properties)  
`advertised.listener`를 설정해주면 되는데, 카프카 클라이언트 또는 커맨드 라인 툴을 브로커와 연결할 때 사용한다.  
이미 실행되고 있는 카프카 브로커의 설정을 변경하고 싶다면 브로커를 재시작해야 하므로 신중히 설정하는 것을 추천한다.  
  
카프카 바이너리가 포함된 폴더에는 브로커와 같이 실행할 주키퍼가 준비되어 있다. 분산 코디네이션 서비스를 제공하는 주키퍼는 `카프카의 클러스터 설정 리더 정보, 컨트롤러 정보`를 담고 있어 카프카를 실행하는 데에 필요한 필수 애플리케이션이다. 주키퍼를 상용환경에서 안전하게 운영하기 위해서는 3대 이상의 서버로 구성하여 사용한다. 주키퍼가 정상적으로 실행되었는지 jps 명령어로 확인할 수 있다. jps는 JVM 프로세스 상태를 보는 도구로서 JVM 위에서 동작하는 주키퍼의 프로세스를 확인할 수 있다.  
`bin/zookeeper-server-start.sh -daemon config/zookeeper.properties`
  
이제 카프카 브로커를 -daemon옵션과 함께 백그라운드 모드로 실행하자.  
tail 명령어로 로그를 확인하여 카프카 브로커가 정상 동작하는지 확인할 수 있다. 카프카 브로커의 로그를 확인하는 것은 매우 중요한데, 카프카 클라이언트를 개발할 떄 뿐만 아니라 카프카 클러스터를 운영할 때 이슈가 발생할 경우 모두 카프카 브로커에 로그가 남기 때문이다.  
  
`tail -f logs/server.log`
  
카프카 브로커에 대한 정보를 가져올 수 있는 명령어를 사용해 카프카 브로커와 정상적으로 연동되는지 확인할 수 있다.  
`bin/kafka-broker-api-versions.sh --bootstrap-server 13.125.222.89:9092`
## 카프카 커맨드 라인 툴
### kafka-topics.sh
토픽이란 카프카에서 데이터를 구분하는 가장 기본적인 개념이다. 마치 RDBMS의 테이블과 유사하다고 할 수 있다.  
토픽을 생성하는 상황은 크게 2가지가 있는데, 첫 번째는 카프카 컨슈머 또는 프로듀서가 브로커에 생성되지 않은 토픽에 대해서 데이터를 요청할 때, 두 번째는 커맨드 라인 툴로 명시적으로 토픽을 생성하는 것이다. 토픽을 효과적으로 유지보수하기 위해서는 토픽을 명시적으로 생성하는 것을 추천한다.  
  
`kafka-topics.sh`를 통해 토픽 관련 명령을 실행할 수 있다.  
```bash
bin/kafka-topics.sh \
--create \
--bootstrap-server my-kafka:9092 \
--topic hello.kafka \
```
클러스터 정보와 토픽 이름은 토픽을 만들기 위한 필수값이다.  
만약 파티션 개수, 복제 개수, 토픽 데이터 유지 기간 옵션들을 지정하여 토픽을 생성하고 싶다면 다음과 같이 명령을 실행하면 된다.  
```bash
bin/kafka-topics.sh \
--create \
--bootstrap-server my-kafka:9092 \
--partitions 3 \
--replication-factor 1 \
--config retention.ms=172800000 \
--topic hello.kafka2 \
```
카프카 클러스터에 생성된 토픽들의 이름을 --list 옵션을 사용하여 확인할 수 있다. 카프카를 운영할 때 토픽이 몇 개나 생성되었는지, 어떤 이름의 토픽이 있는지 확인하기 위해 사용한다.  
```bash
bin/kafka-topics.sh --bootstrap-server my-kafka:9092 --list
```
토픽의 상세 조회는 다음 명령어로 가능하다.  
```bash
bin/kafka-topics.sh --bootstrap-server my-kafka:9092 --describe --topic hello.kafka2
```
여러 대의 브로커로 카프카 클러스터를 운영할 때 토픽의 리더 파티션이 일부 브로커에 몰려있을 수 있는데, 이를 확인하기 위해 --describe 옵션을 사용할 수 있다. 리더 파티션이 일부 브로커에 몰려있는 경우 카프카 클러스터 부하가 특정 브로커들로 몰릴 수 있다.  
부하가 분산되지 못하면 데이터 통신 쏠림 현상으로 인해 네트워크 대역의 이슈가 생길 수 있다.  
  
파티션 개수 변경을 하려면 kafka-topics.sh를 사용해야 하고 토픽 삭제 정책인 리텐션 기간을 변경하려면 kafka-configs.sh를 사용해야 한다.  
### kafka-console-producer.sh
hello.kafka 토픽에 데이터를 넣을 수 있는 kafka-producer.sh 명령어를 실행해 보자.  
토픽에 넣는 데이터는 '레코드(record)'라고 부르며 메시지 키(key)와 메시지 값(value)으로 이루어져 있다.  
메시지 키가 없이 메시지 값만 보내면 키는 null로 기본 설정되어 브로커로 전송된다.  
```bash
bin/kafka-console-producer.sh --bootstrap-server my-kafka:9092 \
--topic hello.kafka
>hello
```
레코드 값은 UTF-8 기반으로 Byte로 변환되고 ByteArraySerializer로만 직렬화된다. 즉, String이 아닌 타입으로는 직렬화하여 전송할 수 없다.  
다른 타입으로 직렬화하여 데이터를 브로커로 전송하고 싶다면 카프카 프로듀서 애플리케이션을 직접 개발해야 한다.  
  
메시지 키를 가지는 레코드는 다음과 같이 전송할 수 있다.  
```bash
bin/kafka-console-producer.sh --bootstrap-server my-kafka:9092 \
--topic hello.kafka \
--property "parse.key=true" \
--property "key.separator=:"
```
key.separator를 명시하지 않으면 기본 설정은 Tab이다.  
메시지 키와 메시지 값을 함께 전송한 레코드는 토픽의 파티션에 저장된다. 메시지 키가 null인 경우에는 프로듀서가 파티션으로 전송할 때 레코드 배치 단위로 라운드 로빈으로 전송한다. 이를 통해 각 파티션에 메시지가 고르게 분배되도록 한다.  
메시지 키가 존재하는 경우에는 키의 해시값을 작성하여 존재하는 파티션 중 한 개에 할당된다. 메시지 키가 동일한 경우에는 동일한 파티션으로 전송된다. 커스텀 파티셔너를 사용할 경우 메시지 키에 따른 파티션 할당이 다르게 동작할 수도 있다.  
  
메시지 키를 가진 레코드의 경우 파티션이 추가되면 파티션과 메시지 키의 일관성이 보장되지 않는다.  
### kafka-console-consumer.sh
kafka-console-consumer.sh 명령어를 통해 레코드를 확인할 수 있다.  
이때 필수 옵션으로 --bootstrap-server에 카프카 클러스터 정보, --topic에 토픽 이름이 필요하다. --from-beginning 옵션을 주면 토픽에 저장된 가장 처음 데이터부터 출력한다.  
```bash
bin/kafka-console-consumer.sh --bootstrap-server my-kafka:9092 \
--topic hello.kafka \
--from-beginning
```
레코드의 메시지 키와 값을 확인하고 싶다면 --property 옵션을 사용하면 된다.  
```bash
bin/kafka-console-consumer.sh --bootstrap-server my-kafka:9092 \
--topic hello.kafka \
--property print.key=true \
--property key.separator="-" \
--group hello-group \
--from-beginning
```
--group 옵션을 통해 신규 컨슈머 그룹을 생성했다. 컨슈머 그룹은 1개 이상의 컨슈머로 이루어져 있으며 이 컨슈머 그룹을 통해 가져간 토픽의 메시지는 가져간 메시지에 대해 커밋(commit)을 한다. 커밋이란 컨슈머가 특정 레코드까지 처리를 완료했다고 레코드의 오프셋 번호를 카프카 브로커에 저장하는 것이다.  
커밋 정보는 `__consumer_offsets` 이름의 내부 토픽에 저장된다.  
### kafka-consumer-groups.sh
hello-group 이름의 컨슈머 그룹으로 생성된 컨슈머로 hello.kafka 토픽의 데이터를 가져갔다. 컨슈머 그룹은 따로 생성하는 명령을 날리지 않고 컨슈머를 동작할 때 컨슈머 그룹 이름을 지정하면 새로 생성된다.  
```bash
bin/kafka-consumer-groups.sh --bootstrap-server my-kafka:9092 --list
hello-group

bin/kafka-consumer-groups.sh --bootstrap-server my-kafka:9092 \
--group hello-group --describe
```
### kafka-verifiable-producer, consumer.sh
kafka-verifiable로 시작하는 2개의 스크립트를 사용하면 String 타입 메시지 값을 코드 없이 주고받을 수 있다. 카프카 클러스터 설치가 완료된 이후에 토픽에 데이터를 전송하여 간단한 네트워크 통신 테스트를 할 때 유용하다.  
  
### kafka-delete-records.sh
이미 적재된 토픽의 데이터를 지울 수 있다. 가장 오래된 데이터(가장 낮은 숫자의 오프셋)부터 특정 시점의 오프셋까지 삭제할 수 있다.  
  
주의할 점은 토픽의 특정 레코드 하나만 삭제되는 것이 아니라 파티션에 존재하는 가장 오래된 오프셋부터 지정한 오프셋까지 삭제된다는 점이다. 카프카에서는 토픽의 파티션에 저장된 특정 데이터만 삭제할 수 없다는 점을 명심해야 한다.  
